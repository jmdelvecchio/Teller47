{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Patterns and rates of soil movement and shallow failures across several small watersheds on the Seward Peninsula, Alaska</b>\n",
    "\n",
    "Del Vecchio et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from matplotlib.gridspec import  GridSpec\n",
    "from matplotlib.lines import Line2D\n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "from contextlib import contextmanager  \n",
    "from matplotlib import ticker, cm\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Point\n",
    "#from rasterstats import zonal_stats\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy.ma as ma\n",
    "import richdem as rd\n",
    "import numpy as np\n",
    "import rasterio.mask\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import fiona\n",
    "import rasterio\n",
    "import xarray\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./Teller_47_Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code to import geospatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional maps from Google Earth Engine (see script)\n",
    "\n",
    "regional_dem = os.path.join(data_path,\"Teller_47_Data_Maps//regional_dem.tif\" )\n",
    "regional_slope = os.path.join(data_path,\"Teller_47_Data_Maps//regional_slope.tif\" )\n",
    "water_vectors = os.path.join(data_path,\"Teller_47_Data_Maps//water_vectors.shp\")\n",
    "\n",
    "t47_dem = rasterio.open(os.path.join(data_path,\"Teller_47_Data_Maps//zoom_dem.tif\"  ))\n",
    "t47_slope = rasterio.open(os.path.join(data_path,\"Teller_47_Data_Maps//zoom_slope.tif\"  ))\n",
    "\n",
    "dem = rasterio.open(regional_dem)\n",
    "slope = rasterio.open(regional_slope)\n",
    "water = gpd.read_file(water_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make water mask\n",
    "water = water[water['water'] == 1]\n",
    "water = water.to_crs('EPSG:32603')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a shapefile from target positions in UTM Zone 3N\n",
    "average_cleaned_final = pd.read_csv(os.path.join(data_path,\"Teller_47_Data_dGPS//target_locs_cleaned.csv\"))\n",
    "geometry = [Point(xy) for xy in zip(average_cleaned_final['Easting_2019_y'], average_cleaned_final['Northing_2019_y'])]\n",
    "sites_3N = gpd.GeoDataFrame(average_cleaned_final, crs=\"EPSG:32603\", geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a zoom-in box\n",
    "sites_3N_box=[\n",
    "            sites_3N.total_bounds[0],\n",
    "              sites_3N.total_bounds[2],\n",
    "              sites_3N.total_bounds[1],\n",
    "              sites_3N.total_bounds[3]\n",
    "             ]\n",
    "box_params = [(sites_3N_box[0],sites_3N_box[3]),\n",
    "              (sites_3N_box[1]-sites_3N_box[0]),\n",
    "              (sites_3N_box[2]-sites_3N_box[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load InSAR hillslope sites (see end of notebook)\n",
    "insar_pts = gpd.read_file((os.path.join(data_path,\"Teller_47_Data_Shapefiles//insar_pts.shp\"))).to_crs(\"EPSG:32603\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to make map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(6,3),dpi=300)\n",
    "\n",
    "# transform rasterio plot to real world coords\n",
    "extent_r=[dem.bounds[0], dem.bounds[2], dem.bounds[1], dem.bounds[3]]\n",
    "extent_t47=[t47_dem.bounds[0], t47_dem.bounds[2], t47_dem.bounds[1], t47_dem.bounds[3]]\n",
    "\n",
    "im0 = rasterio.plot.show(slope, extent=extent_r,\n",
    "                         vmin=0.0,\n",
    "                         vmax=30.0,\n",
    "                         cmap=\"Greys\",\n",
    "                         #alpha=0.5,\n",
    "                         zorder=0,\n",
    "                         ax=ax[0])\n",
    "im1 = rasterio.plot.show(dem, extent=extent_r,\n",
    "                         cmap=\"BrBG_r\",\n",
    "                         ax=ax[0],\n",
    "                         vmax=(np.nanmax(dem.read(1))*0.67), # % of highest elev. non-nan\n",
    "                         alpha=0.5,\n",
    "                        zorder=1)\n",
    "\n",
    "water.plot(color='b',ax=ax[0])\n",
    "\n",
    "insar_pts.plot(ax=ax[0],\n",
    "               marker='*',\n",
    "               edgecolor='k',\n",
    "               color='w',\n",
    "               markersize=20,\n",
    "               linewidth=0.5,\n",
    "              )\n",
    "\n",
    "box = matplotlib.patches.Rectangle(box_params[0],\n",
    "                                   width = box_params[1],\n",
    "                                   height = box_params[2],\n",
    "                                   edgecolor='r',\n",
    "                                   facecolor='none')\n",
    "\n",
    "ax[0].add_patch(box)\n",
    "\n",
    "\n",
    "im0 = rasterio.plot.show(t47_slope, extent=extent_t47,\n",
    "                         vmin=0.0,\n",
    "                         vmax=30.0,\n",
    "                         cmap=\"Greys\",\n",
    "                         #alpha=0.5,\n",
    "                         zorder=0,\n",
    "                         ax=ax[1])\n",
    "im1 = rasterio.plot.show(t47_dem, extent=extent_t47,\n",
    "                         cmap=\"BrBG_r\",\n",
    "                         ax=ax[1],\n",
    "                         vmax=(np.nanmax(dem.read(1))*0.67), # % of highest elev. non-nan\n",
    "                         alpha=0.5,\n",
    "                        zorder=1)\n",
    "im2 = rasterio.plot.show(t47_dem, extent=extent_t47,\n",
    "                         contour=True,\n",
    "                         levels=np.arange(0,np.nanmax(dem.read(1)),50),\n",
    "                         colors=['black'],\n",
    "                         linewidths=1,\n",
    "                         contour_label_kws={\n",
    "                             \"colors\":\"black\",\n",
    "                             \"fontsize\":8,\n",
    "                             \"inline_spacing\":3,\n",
    "                         #\"fmt\":\"%1.0f\"\n",
    "                         },\n",
    "                         ax=ax[1],\n",
    "                         alpha=0.75,\n",
    "                        zorder=2)\n",
    "\n",
    "sites_3N[sites_3N['type'] == 'gcp'].plot(marker='o',\n",
    "                                         edgecolor='k',\n",
    "                                         color='w',\n",
    "                                         markersize=15,\n",
    "                                         linewidth=0.5,\n",
    "                                         ax=ax[1],\n",
    "                                        zorder=3)\n",
    "sites_3N[sites_3N['type'] == 'lobe'].plot(marker='s',\n",
    "                                         edgecolor='k',\n",
    "                                         color='w',\n",
    "                                         markersize=15,\n",
    "                                         linewidth=0.5,\n",
    "                                          ax=ax[1],\n",
    "                                         zorder=3)\n",
    "\n",
    "ax[0].set_ylim((7.19e6, 7.23e6))\n",
    "ax[0].set_xlim((4.2e5, 4.6e5))\n",
    "ax[0].locator_params(axis='x', nbins=3)\n",
    "ax[0].locator_params(axis='y', nbins=3)\n",
    "ax[0].set_xlabel(\"Easting\")\n",
    "ax[0].set_ylabel(\"Northing\")\n",
    "ax[0].text(4.2e5-5000, 7.23e6, \"A\",size=20, weight='bold')\n",
    "ax[0].text(box_params[0][0], box_params[0][1]+500, \"Fig. 1B\",color=\"r\",size=8)\n",
    "\n",
    "\n",
    "ax[1].set_ylim((7.20505e6, 7.2075e6))\n",
    "ax[1].set_xlim((4.415e5, 4.440e5))\n",
    "ax[1].locator_params(axis='x', nbins=3)\n",
    "ax[1].locator_params(axis='y', nbins=3)\n",
    "ax[1].set_xlabel(\"Easting\")\n",
    "ax[1].text(4.415e5-300, 7.2075e6, \"B\",size=20, weight='bold')\n",
    "\n",
    "\n",
    "ax[0].set_facecolor('b')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//Fig_1_map.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental figure: InSAR average displacements (while I'm here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_map = rasterio.open(os.path.join(data_path,\"Teller_47_Data_InSAR//avg_disp171819_utm.tif\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3),dpi=400)\n",
    "\n",
    "# transform rasterio plot to real world coords\n",
    "extent_r=[dem.bounds[0], dem.bounds[2], dem.bounds[1], dem.bounds[3]]\n",
    "extent_t47=[t47_dem.bounds[0], t47_dem.bounds[2], t47_dem.bounds[1], t47_dem.bounds[3]]\n",
    "\n",
    "im0 = rasterio.plot.show(slope, extent=extent_r,\n",
    "                         vmin=0.0,\n",
    "                         vmax=30.0,\n",
    "                         cmap=\"Greys\",\n",
    "                         #alpha=0.5,\n",
    "                         zorder=1,\n",
    "                         ax=ax)\n",
    "im1 = rasterio.plot.show(insar_map, extent=extent_r,\n",
    "                         cmap=\"jet\",\n",
    "                         ax=ax,\n",
    "                         vmin=-0.01,\n",
    "                         vmax=0.1,\n",
    "                         alpha=0.8,\n",
    "                        zorder=2)\n",
    "# For colorbar\n",
    "imx = plt.imshow(insar_map.read(1), extent=extent_r,\n",
    "                         cmap=\"jet\",\n",
    "                         vmin=-0.01,\n",
    "                         vmax=0.1,\n",
    "                         alpha=0.8,\n",
    "                        zorder=0)\n",
    "\n",
    "im2 = rasterio.plot.show(dem, extent=extent_r,\n",
    "                         contour=True,\n",
    "                         levels=np.arange(0,np.nanmax(dem.read(1)),50),\n",
    "                         colors=['black'],\n",
    "                         linewidths=0.5,\n",
    "                         contour_label_kws={\n",
    "                             \"colors\":\"black\",\n",
    "                             \"fontsize\":2,\n",
    "                             \"inline_spacing\":1,\n",
    "                         #\"fmt\":\"%1.0f\"\n",
    "                         },\n",
    "                         ax=ax,\n",
    "                         alpha=0.75,\n",
    "                        zorder=3)\n",
    "\n",
    "water.plot(color='k',ax=ax, zorder=4)\n",
    "\n",
    "insar_pts.plot(ax=ax,\n",
    "               marker='*',\n",
    "               edgecolor='k',\n",
    "               color='w',\n",
    "               markersize=20,\n",
    "               linewidth=0.5,\n",
    "               zorder=5\n",
    "              )\n",
    "\n",
    "cb = fig.colorbar(imx, ax=ax, label=\"Average annual displacement, 2017-2019 (m/yr)\",  orientation='horizontal', fraction=0.04, pad=0.2)\n",
    "\n",
    "ax.set_ylim((7.2e6, 7.215e6))\n",
    "ax.set_xlim((4.275e5, 4.525e5))\n",
    "\n",
    "ax.locator_params(axis='x', nbins=3)\n",
    "ax.locator_params(axis='y', nbins=3)\n",
    "ax.set_xlabel(\"Easting\")\n",
    "ax.set_ylabel(\"Northing\")\n",
    "\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//InSAR_regional.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "# dGPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate displacements from annual GPS position data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,x2,y1,y2):\n",
    "    return (np.absolute((x2-x1)**2 + (y1-y2)**2) ** (1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = pd.read_csv(os.path.join(data_path,\"Teller_47_Data_dGPS/target_locs_cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs['dDist_1819'] = distance(locs['Easting_2018_y'],locs['Easting_2019_y'],locs['Northing_2018_y'],locs['Northing_2019_y'])\n",
    "locs['dDist_1718'] = distance(locs['Easting_2017'],locs['Easting_2018_y'],locs['Northing_2017'],locs['Northing_2018_y'])\n",
    "locs['dDist_1719_avg'] = distance(locs['Easting_2017'],locs['Easting_2019_y'],locs['Northing_2017'],locs['Northing_2019_y'])/2 # Two years of data\n",
    "locs['dElev_1819'] = locs['Elevation_minus_rebar_m_2019'] - locs['Elevation_2018_y'] \n",
    "locs['dElev_1718'] = locs['Elevation_2018_y'] - locs['Elevation_2017'] \n",
    "locs['dElev_1719_avg'] = (locs['Elevation_2019_y'] - locs['Elevation_2017']) /2 # Two years of data\n",
    "\n",
    "locs['slope_normal_1819']=(locs['dDist_1819']**2 + locs['dElev_1819']**2)**(1/2)\n",
    "locs['slope_normal_1718']=(locs['dDist_1718']**2 + locs['dElev_1718']**2)**(1/2)\n",
    "locs['slope_normal_1719']=(locs['dDist_1719_avg']**2 + locs['dElev_1719_avg']**2)**(1/2)\n",
    "\n",
    "\n",
    "\n",
    "locs['position_change_uncertainty'] = np.sqrt((locs['position_uncertainty'] **2) *2)\n",
    "locs['elevation_change_uncertainty'] = np.sqrt((locs['elevation_uncertainty'] **2) *2)\n",
    "locs['slope_normal_change_uncertainty'] =np.sqrt((locs['elevation_uncertainty'] **2) + (locs['position_uncertainty'] **2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.031850\n",
       "1     0.031850\n",
       "2     0.031850\n",
       "3     0.031850\n",
       "4     0.031850\n",
       "        ...   \n",
       "60    0.015925\n",
       "61    0.015925\n",
       "62    0.015925\n",
       "63    0.015925\n",
       "64    0.015925\n",
       "Name: elevation_uncertainty, Length: 65, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs['elevation_uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs.to_csv(\"locs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dataframe into geodataframe\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(locs['Easting_2019_y'], locs['Northing_2019_y'])]\n",
    "sites_3N = gpd.GeoDataFrame(locs, crs=\"EPSG:32603\", geometry=geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Figure 3 displacement map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_change = sites_3N[sites_3N['dElev_1819'] > 0]\n",
    "neg_change = sites_3N[sites_3N['dElev_1819'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3), dpi=300)\n",
    "im0 = rasterio.plot.show(t47_slope, extent=extent_t47,\n",
    "                         vmin=0.0,\n",
    "                         vmax=30.0,\n",
    "                         cmap=\"Greys\",\n",
    "                         #alpha=0.5,\n",
    "                         zorder=0,\n",
    "                         ax=ax)\n",
    "im1 = rasterio.plot.show(t47_dem, extent=extent_t47,\n",
    "                         cmap=\"BrBG_r\",\n",
    "                         ax=ax,\n",
    "                         vmax=(np.nanmax(dem.read(1))*0.67), # % of highest elev. non-nan\n",
    "                         alpha=0.5,\n",
    "                        zorder=1)\n",
    "im2 = rasterio.plot.show(t47_dem, extent=extent_t47,\n",
    "                         contour=True,\n",
    "                         levels=np.arange(0,np.nanmax(dem.read(1)),20),\n",
    "                         colors=['black'],\n",
    "                         linewidths=0.5,\n",
    "                         contour_label_kws={\n",
    "                             \"colors\":\"black\",\n",
    "                             \"fontsize\":6,\n",
    "                             \"inline_spacing\":3,\n",
    "                         #\"fmt\":\"%1.0f\"\n",
    "                         },\n",
    "                         ax=ax,\n",
    "                         alpha=0.75,\n",
    "                        zorder=2)\n",
    "\n",
    "pos_change[pos_change['type'] == 'gcp'].plot(marker='o',\n",
    "                                         edgecolor='k',\n",
    "                                         color='gray',\n",
    "                                         markersize=(pos_change['dElev_1819']+abs(pos_change['dElev_1819'].min()))*100,\n",
    "                                         linewidth=0.5,\n",
    "                                         ax=ax,\n",
    "                                        zorder=3)\n",
    "# sites_3N[sites_3N['type'] == 'lobe'].plot(marker='s',\n",
    "#                                          edgecolor='k',\n",
    "#                                          color='w',\n",
    "#                                          markersize=(sites_3N['dElev_1819']+abs(sites_3N['dElev_1819'].min()))*100,\n",
    "#                                          linewidth=0.5,\n",
    "#                                           ax=ax,\n",
    "#                                          zorder=3)\n",
    "\n",
    "pos_change[pos_change['type'] == 'lobe'].plot(marker='s',\n",
    "                                         edgecolor='k',\n",
    "                                         color='gray',\n",
    "                                         markersize=(pos_change['dElev_1819']+abs(pos_change['dElev_1819'].min()))*100,\n",
    "                                         linewidth=0.5,\n",
    "                                          ax=ax,\n",
    "                                         zorder=3)\n",
    "\n",
    "neg_change[neg_change['type'] == 'gcp'].plot(marker='o',\n",
    "                                         edgecolor='k',\n",
    "                                         color='w',\n",
    "                                         markersize=(neg_change['dElev_1819']+abs(neg_change['dElev_1819'].min()))*100,\n",
    "                                         linewidth=0.5,\n",
    "                                         ax=ax,\n",
    "                                        zorder=3)\n",
    "\n",
    "neg_change[neg_change['type'] == 'lobe'].plot(marker='s',\n",
    "                                         edgecolor='k',\n",
    "                                         color='w',\n",
    "                                         markersize=(neg_change['dElev_1819']+abs(neg_change['dElev_1819'].min()))*100,\n",
    "                                         linewidth=0.5,\n",
    "                                          ax=ax,\n",
    "                                         zorder=3)\n",
    "X = locs['Easting_2018_y'].values\n",
    "Y = locs['Northing_2018_y'].values\n",
    "U = locs['Easting_2019_y']-locs['Easting_2018_y'].values\n",
    "V = locs['Northing_2019_y']-locs['Northing_2018_y'].values\n",
    "ax.quiver(X,Y, U, V,\n",
    "          headwidth=3,\n",
    "          headlength=4,\n",
    "          zorder=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylim((7.20525e6, 7.20725e6))\n",
    "ax.set_xlim((4.42e5, 4.4375e5))\n",
    "ax.locator_params(axis='x', nbins=3)\n",
    "ax.locator_params(axis='y', nbins=3)\n",
    "ax.set_ylabel(\"Northing (m)\")\n",
    "ax.set_xlabel(\"Easting (m)\")\n",
    "\n",
    "\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//Fig_3_vector_map_all.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobe = rasterio.open(os.path.join(data_path,\"Teller_47_Data_Rasters//t47_lobe_clip_fig3.tif\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), dpi=300)\n",
    "\n",
    "im0 = rasterio.plot.show(lobe.read([1,2,3]),\n",
    "                        extent=[lobe.bounds[0], lobe.bounds[2], lobe.bounds[1], lobe.bounds[3]],\n",
    "                         # vmin=0.0,\n",
    "                         # vmax=30.0,\n",
    "                         # cmap=\"Greys\",\n",
    "                         # #alpha=0.5,\n",
    "                         zorder=0,\n",
    "                         ax=ax)\n",
    "im2 = rasterio.plot.show(t47_dem, extent=extent_t47,\n",
    "                         contour=True,\n",
    "                         levels=np.arange(0,np.nanmax(dem.read(1)),10),\n",
    "                         colors=['black'],\n",
    "                         linewidths=0.5,\n",
    "                         contour_label_kws={\n",
    "                             \"colors\":\"black\",\n",
    "                             \"fontsize\":6,\n",
    "                             \"inline_spacing\":3,\n",
    "                         #\"fmt\":\"%1.0f\"\n",
    "                         },\n",
    "                         ax=ax,\n",
    "                         alpha=0.75,\n",
    "                        zorder=2)\n",
    "sites_3N[sites_3N['type'] == 'lobe'].plot(marker='s',\n",
    "                                         edgecolor='k',\n",
    "                                         color='w',\n",
    "                                         markersize=(sites_3N['dElev_1719_avg']+abs(sites_3N['dElev_1719_avg'].min()))*100,\n",
    "                                         linewidth=0.5,\n",
    "                                          ax=ax,\n",
    "                                         zorder=3)\n",
    "X = locs['Easting_2017'].values\n",
    "Y = locs['Northing_2017'].values\n",
    "U = (locs['Easting_2019_y']-locs['Easting_2017'].values)/2\n",
    "V = (locs['Northing_2019_y']-locs['Northing_2017'].values)/2\n",
    "ax.quiver(X,Y, U, V,\n",
    "          headwidth=3,\n",
    "          headlength=4,\n",
    "          zorder=4)\n",
    "ax.set_ylim((7.206625e6, 7.2067e6))\n",
    "ax.set_xlim((4.42625e5, 4.4275e5))\n",
    "ax.locator_params(axis='x', nbins=3)\n",
    "ax.locator_params(axis='y', nbins=3)\n",
    "ax.set_ylabel(\"Northing (m)\")\n",
    "ax.set_xlabel(\"Easting (m)\")\n",
    "\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//Fig_3_vector_map_lobe.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample topographic rasters at GPS points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = [\"t47_slope.tif\", \"t47_acc.tif\", \"t47_radiation.tif\"]\n",
    "stack_names = [\"slope\", \"flow_acc\", \"radiation\"]\n",
    "\n",
    "coords = [(x,y) for x, y in zip(locs['Easting_2019_y'], locs['Northing_2019_y'])]         \n",
    "         \n",
    "for i, raster_file in enumerate(stack):\n",
    "    # Sample the raster at every point location and store values in DataFrame\n",
    "    src = rasterio.open((os.path.join(data_path, \"Teller_47_Data_Rasters\", raster_file)))\n",
    "    col = stack_names[i]\n",
    "    print(col)\n",
    "    locs[col] = [x[0] for x in src.sample(coords)]\n",
    "\n",
    "#https://geopandas.org/en/stable/gallery/geopandas_rasterio_sample.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make boxplots and scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_change = [(locs['dElev_1718'].dropna())* -1,\n",
    "                    (locs[locs['type']=='lobe']['dElev_1819'])* -1,\n",
    "                   (locs[locs['type']=='gcp']['dElev_1819'])* -1]  #Changing sign convention so that subsidence is positive\n",
    "\n",
    "position_change = [locs['dDist_1718'].dropna(),\n",
    "                    locs[locs['type']=='lobe']['dDist_1819'],\n",
    "                   locs[locs['type']=='gcp']['dDist_1819']]\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(7,2.5), dpi=200,\n",
    "                     gridspec_kw={'width_ratios':[1, 1, 2]}\n",
    "                      )\n",
    "ax[0].boxplot(position_change)\n",
    "ax[0].set_xticklabels(['Lobes/n17-18', 'Lobes/n18-19','GCPs/n18-19'], fontsize=8)\n",
    "\n",
    "ax[1].boxplot(elevation_change)\n",
    "ax[1].set_xticklabels(['Lobes/n17-18', 'Lobes/n18-19','GCPs/n18-19'], fontsize=8)\n",
    "\n",
    "regression = sns.regplot(x='slope', y='slope_normal_1819',\n",
    "                         scatter=False,\n",
    "                        data=locs,\n",
    "                         line_kws={\"color\": \"black\",\n",
    "                                  \"lw\":1,\n",
    "                                  'linestyle':'--'},\n",
    "                        ax=ax[2],\n",
    "                        )\n",
    "\n",
    "markers={\"gcp\":\"o\",\"lobe\":\"s\"}\n",
    "for typ in markers:\n",
    "    d = locs[locs['type']==typ]\n",
    "\n",
    "    \n",
    "\n",
    "    im = ax[2].scatter(d['slope'], d['slope_normal_1819'], \n",
    "                s = 30, \n",
    "                c = d['flow_acc'], \n",
    "                cmap='PuBu',\n",
    "               norm=colors.LogNorm(\n",
    "               vmin=locs['flow_acc'].min(),\n",
    "               vmax=locs['flow_acc'].max(),\n",
    "               ),\n",
    "                marker = markers[typ],\n",
    "                edgecolor='k',\n",
    "                       zorder=2\n",
    "               #ax=ax[2]\n",
    "                 )\n",
    "    ime = ax[2].errorbar(d['slope'], d['slope_normal_1819'], \n",
    "                         yerr=d['slope_normal_change_uncertainty'],\n",
    "                         fmt=\"o\",\n",
    "                         ls='none',\n",
    "                         markersize=1,\n",
    "                         c='k',\n",
    "               # s = 30, \n",
    "               #  c = d['flow_acc'], \n",
    "               #  cmap='PuBu',\n",
    "               # norm=colors.LogNorm(\n",
    "               # vmin=locs['flow_acc'].min(),\n",
    "               # vmax=locs['flow_acc'].max(),\n",
    "               # ),\n",
    "               #  marker = markers[typ],\n",
    "               #  edgecolor='k',\n",
    "               # ax=ax[2]\n",
    "                         zorder=1\n",
    "                 )\n",
    "cb = fig.colorbar(im, ax=ax[2], label=\"Drainage area ($m^2$)\")\n",
    "\n",
    "\n",
    "# ax[2].scatter(x=all_displacements['slope'],y=all_displacements['combined'],\n",
    "#               c=all_displacements['flowacc'],\n",
    "#               cmap='PuBu',\n",
    "#               norm=colors.LogNorm(),\n",
    "#               column=[all_displacements['type']],\n",
    "#               edgecolor='black',\n",
    "#               s=50)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('Horizontal change (m)')\n",
    "ax[1].set_ylabel('Subsidence (m)')\n",
    "\n",
    "ax[2].set_ylabel('Slope-normal displacement/n2018-2019 (m)')\n",
    "ax[2].set_xlabel('Slope (deg)')\n",
    "\n",
    "ax[2].locator_params(axis='x', nbins=6)\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//Fig_3_boxes_scatter.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_df = locs.loc[:, ['dDist_1819','dDist_1718','dDist_1719_avg','dElev_1819','dElev_1718','dElev_1719_avg','slope','flow_acc','radiation']]\n",
    "im = sns.pairplot(pairplot_df)\n",
    "#im.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//gps_pairplot.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "# Insar vs meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aggregate climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calm = pd.read_csv(data_path+\"Teller_47_Data_Meteo//CALM_seward.csv\",parse_dates=True)\n",
    "\n",
    "nome = pd.read_csv(data_path+\"Teller_47_Data_Meteo//nome_airport_data_all.csv\",header=5, parse_dates=True, index_col=\"Date\")#.fillna(0)\n",
    "# Clean data and only use complete years of data\n",
    "nome['Year'] = nome.index.year.values.astype(int)\n",
    "nome['Month'] = nome.index.month.values.astype(int)\n",
    "nome['doy'] = nome.index.dayofyear.values.astype(int)\n",
    "nome = nome.loc[nome['Year'].between(1901,2021)]\n",
    "nome[['Precipitation (in)', 'Snowfall (in)']] = nome[['Precipitation (in)', 'Snowfall (in)']].fillna(0)\n",
    "\n",
    "nome['Precip_mm'] = nome['Precipitation (in)'] * 25.4\n",
    "nome['Snow_mm'] = nome['Snowfall (in)'] * 25.4\n",
    "nome['Temp_Mean_C'] = (nome['Mean Temperature (degF)']-32) * (5/9)\n",
    "nome['Cum_precip'] = nome.groupby(by=\"Year\")['Precip_mm'].cumsum()\n",
    "nome['Cum_DDT'] = nome[nome[\"Temp_Mean_C\"] > 0.0].groupby(by=\"Year\")['Temp_Mean_C'].cumcount()\n",
    "nome['DDT_dif'] = nome.groupby(by=\"Year\")['Cum_DDT'].diff()\n",
    "\n",
    "# Get day of year of date of max precip\n",
    "max_precip_doy = nome.groupby(['Year'])[\"Precip_mm\"].idxmax()\n",
    "#https://stackoverflow.com/questions/64865421/find-max-by-year-and-return-date-on-which-max-occurred-in-pandas-dataframe\n",
    "max_precip_doy = max_precip_doy.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now just get times when thaw is happening-ish (DDT +1 from previous day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_thaw = nome.loc[nome['DDT_dif'] == 1]\n",
    "\n",
    "# Get day of year of date of max precip\n",
    "max_precip_doy_thaw = nome_thaw.groupby(['Year'])[\"Precip_mm\"].idxmax()\n",
    "#https://stackoverflow.com/questions/64865421/find-max-by-year-and-return-date-on-which-max-occurred-in-pandas-dataframe\n",
    "max_precip_doy_thaw = max_precip_doy_thaw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,1, figsize=(4,6),\n",
    "                       sharex=True,\n",
    "                       tight_layout=True,\n",
    "                       dpi=200)\n",
    "# fig = plt.figure(figsize=(8,8), dpi=200)\n",
    "# ax = {}\n",
    "# ax[0] = fig.add_subplot(6,1,1)\n",
    "# ax[1] = fig.add_subplot(6,1,2, sharex=ax[0])\n",
    "# ax[2] = fig.add_subplot(6,1,3, sharex=ax[0])\n",
    "# ax[3] = fig.add_subplot(6,1,4, sharex=ax[0])\n",
    "# ax[4] = fig.add_subplot(6,1,5, sharex=ax[0])\n",
    "# ax[5] = fig.add_subplot(6,1,6)\n",
    "\n",
    "\n",
    "ax[0].plot(nome_thaw.groupby(by=\"Year\").max().Precip_mm[:-1])\n",
    "ax[0].set_title(\"Thaw season max daily rainfall (mm)\", fontsize=8)\n",
    "ax[1].plot(nome_thaw.groupby(by=\"Year\").max().Cum_precip[:-1])\n",
    "ax[1].set_title(\"Cumulative thaw season rainfall (mm)\", fontsize=8)\n",
    "\n",
    "\n",
    "sns.lineplot(x=nome_thaw.groupby(by=\"Year\").mean().index, y=nome_thaw.groupby(by=\"Year\").max().Cum_DDT,ax=ax[2])\n",
    "sns.regplot(x=nome_thaw.groupby(by=\"Year\").mean().index, y=nome_thaw.groupby(by=\"Year\").max().Cum_DDT, order=1, scatter=False, \n",
    "                                     line_kws={\"color\": \"black\",\n",
    "                                  \"lw\":1,\n",
    "                                  'linestyle':'--'},\n",
    "            ax=ax[2])\n",
    "# ax[2].plot(nome_thaw.groupby(by=\"Year\").max().Cum_DDT[:-1])\n",
    "ax[2].set_title(\"Cumulative annual degree days of thaw (DDT)\", fontsize=8)\n",
    "ax[2].set_ylim(120)\n",
    "ax[2].set_ylabel(None)\n",
    "# ax[3].plot(nome_thaw.loc[max_precip_doy_thaw, 'Year'], nome_thaw.loc[max_precip_doy_thaw, 'doy'])\n",
    "# ax[3].set_title(\"Day of year of max precip event\", fontsize=8)\n",
    "# ax[3].set_ylim((150,320))\n",
    "sns.lineplot(x=nome_thaw.groupby(by=\"Year\").mean().index, y=nome_thaw.groupby(by=\"Year\").mean()['Temp_Mean_C'],ax=ax[3])\n",
    "sns.regplot(x=nome_thaw.groupby(by=\"Year\").mean().index, y=nome_thaw.groupby(by=\"Year\").mean()['Temp_Mean_C'], order=1, scatter=False,\n",
    "                                                 line_kws={\"color\": \"black\",\n",
    "                                  \"lw\":1,\n",
    "                                  'linestyle':'--'},\n",
    "            ax=ax[3])\n",
    "ax[3].set_ylabel(None)\n",
    "ax[3].set_title(\"Average thaw season temperature, deg C\", fontsize=8)\n",
    "# Get cumulative degree days of thaw at time of largest rainstorm\n",
    "sns.lineplot(x=nome_thaw.loc[max_precip_doy_thaw, 'Year'], y=nome_thaw.loc[max_precip_doy_thaw, 'Cum_DDT'],ax=ax[4])\n",
    "sns.regplot(x=nome_thaw.loc[max_precip_doy_thaw, 'Year'], y=nome_thaw.loc[max_precip_doy_thaw, 'Cum_DDT'], order=1, scatter=False, \n",
    "                                     line_kws={\"color\": \"black\",\n",
    "                                  \"lw\":1,\n",
    "                                  'linestyle':'--'},\n",
    "            ax=ax[4])\n",
    "ax[4].set_title(\"Cumulative DDT on day of max daily rainfall (days)\", fontsize=8)\n",
    "ax[4].set_ylabel(None)\n",
    "ax[4].set_xlabel(None)\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//nome_climate_timeseries_thaw.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.75,1.75), sharex=True, dpi=200)\n",
    "sns.regplot(x=calm['Year'], y=calm['Council_ALT'],ax=ax,scatter_kws={'s':10})\n",
    "sns.regplot(x=calm['Year'], y=calm['Kougarok_ALT'],ax=ax,scatter_kws={'s':10})\n",
    "ax.set_title(\"End of season active layer depths (cm)\", fontsize=8)\n",
    "ax.set_xlim((1998,2022))\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig('.//Teller_47_Figures//Teller_47_Figures_in_progress//calm_vs_climate.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowing that InSAR data are on a 12 day cycle we can just get 12-day averages/sums\n",
    "# https://www.statology.org/pandas-moving-average-by-group\n",
    "nome['C_mean_12day'] = nome.groupby(['Year'])['Temp_Mean_C'].transform(lambda x: x.rolling(12,1).mean())\n",
    "nome['P_cum_12day'] = nome.groupby(['Year'])['Precip_mm'].transform(lambda x: x.rolling(12,1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate InSAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_df = pd.read_csv(data_path+\"Teller_47_Data_InSAR//insar_site_displacements.csv\")\n",
    "insar_df['year'] = insar_df['year'].astype(int)\n",
    "insar_df['J1_diff'] = insar_df.groupby(['year'])['J1'].diff()\n",
    "insar_df['J2_diff'] = insar_df.groupby(['year'])['J2'].diff()\n",
    "insar_df['J3_diff'] = insar_df.groupby(['year'])['J3'].diff()\n",
    "insar_df['J4_diff'] = insar_df.groupby(['year'])['J4'].diff()\n",
    "insar_df['J5_diff'] = insar_df.groupby(['year'])['J5'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_df['site_composite_mean'] = insar_df[['J1','J2','J3','J4','J5']].mean(axis=1)\n",
    "insar_df['site_composite_std'] = insar_df[['J1','J2','J3','J4','J5']].std(axis=1)\n",
    "insar_df['std_pos'] = insar_df['site_composite_mean']+insar_df['site_composite_std']\n",
    "insar_df['std_neg'] = insar_df['site_composite_mean']-insar_df['site_composite_std']\n",
    "\n",
    "insar_df['diff_composite_mean'] = insar_df[['J1_diff','J2_diff','J3_diff','J4_diff','J5_diff']].mean(axis=1)\n",
    "insar_df['diff_composite_std'] = insar_df[['J1_diff','J2_diff','J3_diff','J4_diff','J5_diff']].std(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_df['Date'] = pd.to_datetime(insar_df['year'] *1000 + insar_df['doy'], format='%Y%j')\n",
    "insar_df['Date'] = pd.to_datetime(insar_df['Date'], format='%Y-%m-%d')\n",
    "# originally format='%Y%j'\n",
    "insar_df.set_index('Date', inplace=True)\n",
    "insar_df.drop('doy', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_meteo_combined = pd.merge(nome, insar_df, how=\"outer\",right_index=True, left_index=True,\n",
    "                                #on=\"Date\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot climate vs InSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorlist = ['b','r','g']\n",
    "years = [\"2017\",\"2018\",\"2019\"]\n",
    "\n",
    "fig, ax = plt.subplots(5,1, figsize=(4,8), dpi=200, sharex=True)\n",
    "\n",
    "for i, (year, group) in enumerate(insar_meteo_combined.groupby(by='year')):\n",
    "    ax[0].plot(group['doy'], group['site_composite_mean'], c=colorlist[i], label=years[i])\n",
    "    ax[0].set_title(\"Cumulative displacement (inter-site average) (m)\")\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(group['doy'], group['diff_composite_mean'], c=colorlist[i])\n",
    "    ax[1].set_title(\"Mean displacement between satellite passes (m)\")\n",
    "    ax[1].errorbar(group['doy'], group['diff_composite_mean'], yerr=group['diff_composite_std'], alpha=.5, c=colorlist[i])\n",
    "    ax[2].plot(group['doy'], group['Cum_precip'], c=colorlist[i])\n",
    "    ax[2].set_title(\"Annual cumulative precipitation (mm)\")\n",
    "    ax[3].scatter(group['doy'], group['C_mean_12day'], c=colorlist[i], s=10)\n",
    "    ax[3].plot(group['doy'], group['C_mean_12day'], c=colorlist[i], alpha=0.2)\n",
    "    ax[3].set_title(\"Mean temperature of dates between satellite passes (deg C)\")\n",
    "    ax[4].scatter(group['doy'], group['P_cum_12day'], c=colorlist[i], s=10)\n",
    "    ax[4].plot(group['doy'], group['P_cum_12day'], c=colorlist[i], alpha=0.2)\n",
    "    ax[4].set_title(\"Cumulative precipitation in days between satellite passes (mm)\")\n",
    "    ax[4].set_xlabel(\"Day of year\")\n",
    "    #ax.errorbar(group['doy'], group['site_composite_mean'], yerr=group['site_composite_mean']+group['diff_composite_std'])\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//insar_vs_meteo.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bonus figures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(6,3), dpi=100, sharey=True)\n",
    "for i, site in enumerate(['J1_diff','J2_diff','J3_diff','J4_diff','J5_diff']):\n",
    "    im = ax[0].scatter(insar_meteo_combined['Cum_precip'],insar_meteo_combined[site],c=insar_meteo_combined['year'],cmap='viridis',edgecolor='k')\n",
    "    im2 = ax[1].scatter(insar_meteo_combined['Cum_DDT'],insar_meteo_combined[site],c=insar_meteo_combined['year'],cmap='viridis',edgecolor='k')\n",
    "ax[0].set_xlabel(\"yearly cumulative precipitation /nat time of sat pass\")\n",
    "ax[1].set_xlabel(\"yearly cumulative DDT/n at time of sat pass\")\n",
    "ax[0].set_ylabel(\"movement between sat passes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(6,3), dpi=100, sharey=True)\n",
    "for i, site in enumerate(['J1_diff','J2_diff','J3_diff','J4_diff','J5_diff']):\n",
    "    im = ax[0].scatter(insar_meteo_combined['P_cum_12day'],insar_meteo_combined[site],c=insar_meteo_combined['year'],cmap='viridis',edgecolor='k')\n",
    "    im2 = ax[1].scatter(insar_meteo_combined['C_mean_12day'],insar_meteo_combined[site],c=insar_meteo_combined['year'],cmap='viridis',edgecolor='k')\n",
    "ax[0].set_xlabel(\"cumulative precipitation /nof 12 days before sat pass\")\n",
    "ax[1].set_xlabel(\"mean temp of 12 days/n before sat pass\")\n",
    "ax[0].set_ylabel(\"movement between sat passes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Slope stability - modeled vs observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SHALSTAB model of Montgomery and Dietrich (1994)](https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1029/93WR02979?casa_token=vJQ2NGNS82oAAAAA:obDGuoYXpnRkNKJfjXDhhWeQpUtJEy79XBb_eaRFalD2iSjzrXz5JUh_5_1y91WT1Qn3INazspBQllc) and constants to compare against [Mithan et al 2020](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL092264?casa_token=KJynib3aO6kAAAAA%3AxN8ZEirJAHu_58RXNywm_r2wlYQtc0i44WpvXrCJDgA3Rimlc_7NleBwcRR5CDDJ3WqrpYq3xhZq8g) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHALSTAB model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = rasterio.open(\"new_slope_2m.tif\", masked=True)\n",
    "slope_data=slope.read(1)\n",
    "slope_data[slope_data < 0.0] =np.nan\n",
    "drainage_area = rasterio.open(data_path+'Teller_47_Data_Rasters//t47_acc.tif', masked=True)\n",
    "a = drainage_area.read(1).astype(np.float32)\n",
    "a[a < 0.0] =np.nan\n",
    "a[a == 0.0] =1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SHALSTAB constants and calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_normal_soil_thickness = np.cos(np.radians(slope_data))\n",
    "\n",
    " #flow accumulation [m^2] (flow acc currently in pixels,\n",
    "#would mutliply by 2 for drainage area in m2 since 2m DEM but since\n",
    "#'b' is length of countour also 2 m, they cancel out)\n",
    "\n",
    "q_aug = .05; #[m/day] rain Aug 2 2020\n",
    "z = 1; #active layer thickness, [m]\n",
    "tanphi = .84; # original; tan (40 degrees) internal angle of friction\n",
    "s_w_dens = 2; #ratio of density of saturated soil to water \n",
    "Ksat_maybe = 2.2; #m/day if 1/3 is organic and 2/3 is mineral \n",
    "\n",
    "##For reference, Mithan et al used:\n",
    "# tanphi = 0.48 (for 26 degrees) and tanphi=0.32 (for 18 degrees), Harris and Lewkowicz (2000). \n",
    "# s_w_dens = 1.88 (H and L)\n",
    "# z=1.5 (Harris et al. 2008)\n",
    "#Ksat = 9 E-4 to 9 E-1 (Anderson and Anderson)\n",
    "\n",
    "q_T = q_aug / (Ksat_maybe * z * np.cos(np.radians(slope_data)))\n",
    "\n",
    "W = q_aug * a * (Ksat_maybe * z * np.cos(np.radians(slope_data))) * np.sin(np.radians(slope_data))\n",
    "\n",
    "q_cr_T = ((np.sin(np.radians(slope_data)) * (s_w_dens)) / a ) * (1 -  (np.tan(np.radians(slope_data)) / tanphi));\n",
    "#critical rainfall / transmissivity\n",
    "\n",
    "q_cr_K = ((np.sin(np.radians(slope_data)) * (s_w_dens)) / a ) * (1 -  (np.tan(np.radians(slope_data)) / tanphi)) * z * slope_normal_soil_thickness;\n",
    "#critical rainfall / hydraulic conductivity [T = K cos(theta) z]\n",
    "\n",
    "k_aug_crit = q_aug / ((np.sin(np.radians(slope_data)) * (s_w_dens)) / a )* (1 -  (np.tan(np.radians(slope_data)) / tanphi)) * z * slope_normal_soil_thickness;\n",
    "#hydraulic conductivity that just crosses failure threshold for Aug 2\n",
    "#rainfall event\n",
    "\n",
    "q_cr= ((np.sin(np.radians(slope_data)) * (s_w_dens)) / a ) * (1 -  (np.tan(np.radians(slope_data)) / tanphi)) * z * slope_normal_soil_thickness * Ksat_maybe;\n",
    "\n",
    "# Make critical rainfall mm for plotting \n",
    "q_cr_plot=q_cr*1000\n",
    "\n",
    "# Make zeros very smol so logarithms work\n",
    "q_cr_plot[q_cr_plot <= 0.0] = 1E-7\n",
    "\n",
    "# Make critical rainfall mm for plotting \n",
    "q_cr_T_plot=q_cr_T*1000\n",
    "\n",
    "# Make zeros very smol so logarithms work\n",
    "q_cr_T_plot[q_cr_T_plot <= 0.0] = 1E-7\n",
    "\n",
    "# with rasterio.open(data_path+'Teller_47_Data_Rasters//t47_dem.tif') as src:\n",
    "#     out_meta = src.meta.copy()\n",
    "#     with rasterio.open(\"q_cr.tif\",\"w\",**out_meta) as dest:\n",
    "#         dest.write(q_cr_plot,1)\n",
    "with rasterio.open(\"new_slope_2m.tif\", masked=True) as src:\n",
    "    out_meta = src.meta.copy()\n",
    "    with rasterio.open(\"q_cr.tif\",\"w\",**out_meta) as dest:\n",
    "        dest.write(q_cr_plot,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get topographic statistics of mapped failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load and clean shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# footprint_2018 = gpd.read_file(data_path+'Teller_47_Data_Shapefiles//2018UASExtent.shp')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# footprint_2018= footprint_2018.to_crs('epsg:32603')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# footprint_2018[\"area (m2)\"] = footprint_2018['geometry'].area\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# footprint_2019[\"area (m2)\"] = footprint_2019['geometry'].area\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# footprint_2019.to_file(data_path+'Teller_47_Data_Shapefiles//footprint_2019.shp')\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m footprint_2018 \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_file(data_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeller_47_Data_Shapefiles\u001b[39m\u001b[38;5;130;01m//\u001b[39;00m\u001b[38;5;124mfootprint_2018.shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m footprint_2019 \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(data_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeller_47_Data_Shapefiles\u001b[39m\u001b[38;5;130;01m//\u001b[39;00m\u001b[38;5;124mfootprint_2019.shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "# footprint_2018 = gpd.read_file(data_path+'Teller_47_Data_Shapefiles//2018UASExtent.shp')\n",
    "# footprint_2018= footprint_2018.to_crs('epsg:32603')\n",
    "# footprint_2018[\"area (m2)\"] = footprint_2018['geometry'].area\n",
    "# footprint_2018.to_file(data_path+'Teller_47_Data_Shapefiles//footprint_2018.shp')\n",
    "\n",
    "# footprint_2019 = gpd.read_file(data_path+'Teller_47_Data_Shapefiles//TL47_2019_ImageryFootprint.shp')\n",
    "# footprint_2019= footprint_2019.to_crs('epsg:32603')\n",
    "# footprint_2019[\"area (m2)\"] = footprint_2019['geometry'].area\n",
    "# footprint_2019.to_file(data_path+'Teller_47_Data_Shapefiles//footprint_2019.shp')\n",
    "\n",
    "footprint_2018 = gpd.read_file(data_path+'Teller_47_Data_Shapefiles//footprint_2018.shp')\n",
    "footprint_2019 = gpd.read_file(data_path+'Teller_47_Data_Shapefiles//footprint_2019.shp')\n",
    "\n",
    "# footprint_all = gpd.GeoDataFrame(pd.concat([footprint_2019, footprint_2018]))\n",
    "# footprint_all.to_file(data_path+'Teller_47_Data_Shapefiles//footprint_all.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample slope and area for every coordinate in the UAS boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Resample and clip drainage area raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinf_raster = rxr.open_rasterio(data_path+'Teller_47_Data_Rasters//t47_acc.tif', masked=True)\n",
    "\n",
    "da_clipped = dinf_raster.rio.clip(footprint_all.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this next part is before I became aware of `gdalwarp` `-tr` and `-tap`, oh well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get  all coordinates in 2 m dinf raster\n",
    "\n",
    "(X_c, Y_c) = np.meshgrid(da_clipped.x.values, da_clipped.y.values)\n",
    "\n",
    "X_c = X_c.reshape((np.prod(X_c.shape),))\n",
    "Y_c = Y_c.reshape((np.prod(Y_c.shape),))\n",
    "\n",
    "coords = [(x,y) for x, y in zip(X_c, Y_c)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for sure an additional obscenely inefficient way of doing this but shrug, it's Friday afternoon \n",
    "\n",
    "geometry = [Point(xy) for xy in coords]\n",
    "points = gpd.GeoDataFrame(coords, crs=\"EPSG:32603\", geometry=geometry)\n",
    "points_2018 = gpd.sjoin(points, footprint_2018, op='within')\n",
    "points_2019 = gpd.sjoin(points, footprint_2019, op='within')\n",
    "\n",
    "coords_2018 = [(x,y) for x,y in zip(points_2018['geometry'].x , points_2018['geometry'].y)]\n",
    "coords_2019 = [(x,y) for x,y in zip(points_2019['geometry'].x , points_2019['geometry'].y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Sample slope and area for every coordiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with fiona.open(data_path+'Teller_47_Data_Shapefiles//footprint_all.shp', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "with rasterio.open('new_slope.tif', masked=True) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "with rasterio.open('new_slope_clipped.tif', \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "    \n",
    "with fiona.open(data_path+'Teller_47_Data_Shapefiles//footprint_all.shp', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "with rasterio.open(data_path+'Teller_47_Data_Rasters//t47_acc.tif', masked=True) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "with rasterio.open(data_path+'Teller_47_Data_Rasters//t47_acc_clipped.tif', \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points_2018 = pd.DataFrame()\n",
    "df_points_2019 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = rasterio.open(data_path+'Teller_47_Data_Rasters//t47_acc_clipped.tif', masked=True)\n",
    "src = raster\n",
    "df_points_2018['dinf'] = [x[0] for x in src.sample(coords_2018)]\n",
    "print('done dinf')\n",
    "raster.close()\n",
    "\n",
    "raster = rasterio.open('new_slope_clipped.tif', masked=True)\n",
    "src = raster\n",
    "df_points_2018['slope'] = [x[0] for x in src.sample(coords_2018)]\n",
    "raster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = rasterio.open(data_path+'Teller_47_Data_Rasters//t47_acc_clipped.tif', masked=True)\n",
    "src = raster\n",
    "df_points_2019['dinf'] = [x[0] for x in src.sample(coords_2019)]\n",
    "print('done dinf')\n",
    "# raster.close()\n",
    "\n",
    "raster = rasterio.open('new_slope_clipped.tif', masked=True)\n",
    "src = raster\n",
    "df_points_2019['slope'] = [x[0] for x in src.sample(coords_2019)]\n",
    "raster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points_2018 = df_points_2018[df_points_2018['dinf'] > 0.0]\n",
    "df_points_2019 = df_points_2019[df_points_2019['dinf'] > 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get mapped failures shapefile and turn them into points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys_2018 = gpd.read_file(data_path+'Teller_47_Data_Shapefiles//poly_failure_TL47_2018_jcr.shp')\n",
    "polys_2018 = polys_2018.to_crs('epsg:32603')\n",
    "polys_2018[\"area (m2)\"] = polys_2018['geometry'].area\n",
    "polys_2019 = gpd.read_file(data_path + 'Teller_47_Data_Shapefiles//2019_Failure_merged_unique.shp')\n",
    "polys_2019 = polys_2019.to_crs('epsg:32603')\n",
    "polys_2019[\"area (m2)\"] = polys_2019['geometry'].area\n",
    "\n",
    "#https://gis.stackexchange.com/questions/218450/getting-polygon-areas-using-geopandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make heatmaps for 2018 and 2019 failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I made a function to do this I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts = (int) number of bins for slope-area space\n",
    "# res = (float, can be, i guess) raster resolution\n",
    "def make_heatmap(polys, slope_raster, area_raster, pts, res):\n",
    "    \n",
    "    polys = gpd.read_file(polys)\n",
    "    polys = polys.to_crs('epsg:32603')\n",
    "    \n",
    "    polys[\"area (m2)\"] = polys['geometry'].area\n",
    "    \n",
    "    # Do zonal stats\n",
    "    dinf_stats = zonal_stats(polys, area_raster, all_touched=True)\n",
    "    slope_stats = zonal_stats(polys, slope_raster, all_touched=True)\n",
    "    \n",
    "    df_dinf = pd.DataFrame(dinf_stats).add_prefix('dInf_')\n",
    "    df_slope = pd.DataFrame(slope_stats).add_prefix('slope_')\n",
    "\n",
    "    df_stats = pd.merge(df_dinf, df_slope, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    df_stats[\"area (m2)\"] = polys['geometry'].area\n",
    "    \n",
    "    drops = df_stats.dropna()\n",
    "    \n",
    "    # Make heatmap\n",
    "    # pts is number of spacings in the bins in slope-area space\n",
    "    slope_array=np.linspace(7,25,num=pts)\n",
    "    da_array=np.geomspace(1e1,1e4,num=pts)\n",
    "\n",
    "    df_stats['bin_dinf'] = pd.cut(df_stats['dInf_max'],bins=da_array, labels=range(len(da_array)-1)\n",
    "                                 )\n",
    "    df_stats['bin_slope'] = pd.cut(df_stats['slope_max'],bins=slope_array, labels=range(len(slope_array)-1))\n",
    "                                   \n",
    "    heatmap_df = df_stats\n",
    "                                  \n",
    "    df_out = df_stats.groupby(['bin_slope','bin_dinf'])['area (m2)']\n",
    "\n",
    "    heatmap_arr = df_out.sum().sort_index().values.reshape(len(slope_array)-1,len(da_array)-1)\n",
    "    \n",
    "    heatmap_arr = ma.masked_where((heatmap_arr == 0), heatmap_arr)\n",
    "    \n",
    "    return heatmap_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts=40\n",
    "slope_array=np.linspace(7,25,num=pts)\n",
    "da_array=np.geomspace(1e1,1e4,num=pts)\n",
    "heatmap_2018 = make_heatmap(data_path+'Teller_47_Data_Shapefiles//poly_failure_TL47_2018_jcr.shp', \"new_slope.tif\", data_path+'Teller_47_Data_Rasters//t47_acc.tif', 40, 2)\n",
    "heatmap_2019 = make_heatmap(data_path+'Teller_47_Data_Shapefiles//2019_Failure_merged_unique.shp', \"new_slope.tif\", data_path+'Teller_47_Data_Rasters//t47_acc.tif', 40, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a heatmap for the points in each years' UAV survey footprint for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points_2018['bin_dinf'] = pd.cut(df_points_2018['dinf'],bins=da_array, labels=range(len(da_array)-1)\n",
    "                             )\n",
    "df_points_2018['bin_slope'] = pd.cut(df_points_2018['slope'],bins=slope_array, labels=range(len(slope_array)-1)\n",
    "                              )\n",
    "df_out_points = df_points_2018.groupby(['bin_slope','bin_dinf'])['slope']\n",
    "counts = df_out_points.count().sort_index().values.reshape(len(slope_array)-1,len(da_array)-1)\n",
    "counts = ma.masked_where((counts == 0), counts)\n",
    "total_area_in_bin_2018 = counts * 2 # counts is pixels, pixel is 2 m^2\n",
    "\n",
    "# prop_bin_failure_area = arr/total_area_in_bin\n",
    "# prop_bin_failure_area[prop_bin_failure_area > .25] = 0.25\n",
    "\n",
    "\n",
    "\n",
    "df_points_2019['bin_dinf'] = pd.cut(df_points_2019['dinf'],bins=da_array, labels=range(len(da_array)-1)\n",
    "                             )\n",
    "df_points_2019['bin_slope'] = pd.cut(df_points_2019['slope'],bins=slope_array, labels=range(len(slope_array)-1)\n",
    "                              )\n",
    "df_out_points = df_points_2019.groupby(['bin_slope','bin_dinf'])['slope']\n",
    "counts = df_out_points.count().sort_index().values.reshape(len(slope_array)-1,len(da_array)-1)\n",
    "counts = ma.masked_where((counts == 0), counts)\n",
    "total_area_in_bin_2019 = counts * 2 # counts is pixels, pixel is 2 m^2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(11,4),dpi=200, sharey=True)\n",
    "\n",
    "im0 = ax[0].imshow(total_area_in_bin_2018, cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               origin='lower')\n",
    "\n",
    "# This is to fake log bins without making the axis truly log\n",
    "ax[0].set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax[0].set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "divider = make_axes_locatable(ax[0])\n",
    "# Add an axes to the right of the main axes.\n",
    "cax0 = divider.append_axes(\"top\", size=\"5%\", pad=\"10%\")\n",
    "cb0 = fig.colorbar(im0, cax=cax0, orientation=\"horizontal\")\n",
    "cb0.set_label('Total area in each slope-area bin, m^2', labelpad=-40);\n",
    "ax[0].set_ylabel('Slope (degrees)')\n",
    "ax[0].set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "im1 = ax[1].imshow(heatmap_2018, cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               origin='lower')\n",
    "\n",
    "ax[1].set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax[1].set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "divider = make_axes_locatable(ax[1])\n",
    "# Add an axes to the right of the main axes.\n",
    "cax1 = divider.append_axes(\"top\", size=\"5%\", pad=\"10%\")\n",
    "cb1 = fig.colorbar(im1, cax=cax1, orientation=\"horizontal\")\n",
    "cb1.set_label('Area slope failures in bin, m^2', labelpad=-40);\n",
    "ax[1].set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "im2 = ax[2].imshow((heatmap_2018/total_area_in_bin_2018), cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               origin='lower')\n",
    "\n",
    "ax[2].set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax[2].set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "divider = make_axes_locatable(ax[2])\n",
    "# Add an axes to the right of the main axes.\n",
    "cax2 = divider.append_axes(\"top\", size=\"5%\", pad=\"10%\")\n",
    "cb2 = fig.colorbar(im2, cax=cax2, orientation=\"horizontal\")\n",
    "cb2.set_label('% of total area containting failures', labelpad=-40);\n",
    "ax[2].set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//2018_failures_in_slope_area_space.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(11,4),dpi=200, sharey=True)\n",
    "\n",
    "im0 = ax[0].imshow(total_area_in_bin_2019, cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               origin='lower')\n",
    "\n",
    "# This is to fake log bins without making the axis truly log\n",
    "ax[0].set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax[0].set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "divider = make_axes_locatable(ax[0])\n",
    "# Add an axes to the right of the main axes.\n",
    "cax0 = divider.append_axes(\"top\", size=\"5%\", pad=\"10%\")\n",
    "cb0 = fig.colorbar(im0, cax=cax0, orientation=\"horizontal\")\n",
    "cb0.set_label('Total area in each slope-area bin, m^2', labelpad=-40);\n",
    "ax[0].set_ylabel('Slope (degrees)')\n",
    "ax[0].set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "im1 = ax[1].imshow(heatmap_2019, cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               origin='lower')\n",
    "\n",
    "ax[1].set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax[1].set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "divider = make_axes_locatable(ax[1])\n",
    "# Add an axes to the right of the main axes.\n",
    "cax1 = divider.append_axes(\"top\", size=\"5%\", pad=\"10%\")\n",
    "cb1 = fig.colorbar(im1, cax=cax1, orientation=\"horizontal\")\n",
    "cb1.set_label('Area slope failures in bin, m^2', labelpad=-40);\n",
    "ax[1].set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "im2 = ax[2].imshow((heatmap_2019/total_area_in_bin_2019), cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               origin='lower')\n",
    "\n",
    "ax[2].set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax[2].set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "divider = make_axes_locatable(ax[2])\n",
    "# Add an axes to the right of the main axes.\n",
    "cax2 = divider.append_axes(\"top\", size=\"5%\", pad=\"10%\")\n",
    "cb2 = fig.colorbar(im2, cax=cax2, orientation=\"horizontal\")\n",
    "cb2.set_label('% of total area containting failures', labelpad=-40);\n",
    "ax[2].set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//2019_failures_in_slope_area_space.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Steepness vs failure location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(slope_array[:-1], da_array[:-1])\n",
    "zz = xx * np.sqrt(yy) #Theodoratos and Kirchner, 2020 and Litwin et al 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt(x):\n",
    "    s = f\"{x:.1f}\"\n",
    "    if s.endswith(\"0\"):\n",
    "        s = f\"{x:.0f}\"\n",
    "    return rf\"{s}\" if plt.rcParams[\"text.usetex\"] else f\"{s}\"\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,4),dpi=200)\n",
    "#Y axis is rows in reshape (first value in reshape)\n",
    "\n",
    "\n",
    "\n",
    "im = ax.imshow(heatmap_2018, cmap='autumn_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               vmax=35,\n",
    "#                extent=[0, len(da_array)-1, 0, len(slope_array)-1],\n",
    "               #                norm=colors.LogNorm(),\n",
    "               origin='lower')\n",
    "\n",
    "# im3 = ax.imshow(heatmap_differece, cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "#                extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "#                origin='lower')\n",
    "\n",
    "\n",
    "# divider = make_axes_locatable(ax)\n",
    "# # Add an axes to the right of the main axes.\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=\"2%\")\n",
    "# cb = fig.colorbar(im, cax=cax)\n",
    "# cb.set_label('Area of failures (m^2)', rotation=270, labelpad=20);\n",
    "# #ax.set_xscale('log')\n",
    "\n",
    "CS = ax.contour(zz,extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],colors='k')\n",
    "ax.clabel(CS, CS.levels, inline=True, fmt=fmt, fontsize=10, colors='k')\n",
    "\n",
    "ax.set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax.set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "\n",
    "ax.set_xlim(600)\n",
    "ax.set_ylabel('Slope (degrees)')\n",
    "ax.set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "fig.suptitle(\"Topographic steepness vs/nfailure location, pre-2019\",\n",
    "             y=0.98\n",
    "            )\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//steepness_vs_failures_pre2019.png\", bbox_inches=\"tight\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,4),dpi=200)\n",
    "#Y axis is rows in reshape (first value in reshape)\n",
    "\n",
    "\n",
    "\n",
    "im = ax.imshow(heatmap_2019, cmap='autumn_r', interpolation='none', aspect='auto',\n",
    "               extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "               \n",
    "#                extent=[0, len(da_array)-1, 0, len(slope_array)-1],\n",
    "               #                norm=colors.LogNorm(),\n",
    "               origin='lower')\n",
    "\n",
    "# im3 = ax.imshow(heatmap_differece, cmap='plasma_r', interpolation='none', aspect='auto',\n",
    "#                extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],\n",
    "#                origin='lower')\n",
    "\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "# Add an axes to the right of the main axes.\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=\"2%\")\n",
    "cb = fig.colorbar(im, cax=cax)\n",
    "cb.set_label('Area of failures in slope-area bin ($m^2$)', rotation=270, labelpad=20);\n",
    "#ax.set_xscale('log')\n",
    "\n",
    "CS = ax.contour(zz,extent=[np.min(da_array), np.max(da_array), np.min(slope_array), np.max(slope_array)],colors='k')\n",
    "ax.clabel(CS, CS.levels, inline=True, fmt=fmt, fontsize=10, colors='k')\n",
    "ax.set_xticks([0, np.max(da_array)*.33, np.max(da_array)*.66, np.max(da_array)])\n",
    "ax.set_xticklabels([int(da_array[0]), int(round(da_array[int(pts*.33)],0)), int(round(da_array[int(pts*.67)],0)), int(da_array[pts-1])])\n",
    "ax.set_xlim(600)\n",
    "ax.set_ylabel('Slope (degrees)')\n",
    "ax.set_xlabel('Drainage area (m^2)')\n",
    "\n",
    "fig.suptitle(\"Topographic steepness vs failure location\",\n",
    "             y=.95\n",
    "            )\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//steepness_vs_failures_proportions\", bbox_inches=\"tight\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make final figure - q_crit and shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys_2019['centroid'] = polys_2019.centroid\n",
    "points_2019 = polys_2019.copy().set_geometry(polys_2019['centroid'])\n",
    "\n",
    "polys_2018['centroid'] = polys_2018.centroid\n",
    "points_2018 = polys_2018.copy().set_geometry(polys_2018['centroid'])\n",
    "\n",
    "with rasterio.open('new_slope.tif', masked=True) as slope:\n",
    "    extent_slope=[slope.bounds[0], slope.bounds[2], slope.bounds[1], slope.bounds[3]]\n",
    "# poly_extent = np.asarray(UAS.geometry.total_bounds)[[0,2,1,3]]\n",
    "# test_bounds = np.asarray(slope.bounds)[[0,2,1,3]]*3\n",
    "\n",
    "qt_digi = np.digitize((np.log(q_cr_T_plot)), np.array(np.arange(-5.0,5.0,0.5)), right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(7,4),dpi=300)\n",
    "im0 = rasterio.plot.show(t47_slope, extent=extent_slope,\n",
    "                         vmin=0.0,\n",
    "                         vmax=30.0,\n",
    "                         cmap=\"Greys\",\n",
    "                         #alpha=0.5,\n",
    "                         zorder=0,\n",
    "                         ax=ax[0])\n",
    "\n",
    "with rasterio.open(\"q_cr.tif\", masked=True) as q_cr:      \n",
    "    qcr_colors = ax[0].imshow(q_cr.read(1), cmap=cmap, norm=norm,\n",
    "                           #vmin=10, vmax=60\n",
    "                          )\n",
    "    im1 = rasterio.plot.show(q_cr,cmap=cmap, norm=norm, \n",
    "                             #vmin=10, vmax=60,\n",
    "                             extent=extent_slope,\n",
    "                             ax=ax[0], alpha=0.67,\n",
    "                            )\n",
    "b2 = footprint_2018.boundary.plot(ax=ax[0],  color='r', alpha=0.7, zorder=1)\n",
    "b1 = points_2018.plot(ax=ax[0],\n",
    "                         color='r',\n",
    "                         markersize=10,\n",
    "                         edgecolor='k',\n",
    "                         linewidth=0.5,\n",
    "                         zorder=2)\n",
    "\n",
    "b3 = footprint_2019.boundary.plot(ax=ax[0],  color='c', alpha=0.7,zorder=1)\n",
    "b4 = points_2019.plot(ax=ax[0],\n",
    "                         color='c',\n",
    "                         markersize=10,\n",
    "                         edgecolor='k',\n",
    "                         linewidth=0.5,\n",
    "                         zorder=2)\n",
    "\n",
    "cbar = fig.colorbar(qcr_colors, ax=ax[0], orientation='horizontal',\n",
    "                    label='$q_{cr}$ (mm/day)',\n",
    "                    fraction=0.04,\n",
    "                    #pad=0.1\n",
    "                   )\n",
    "mod_ticks = cbar.ax.get_xticks().astype(int).astype(str)\n",
    "mod_ticks[-1:] = '>60'\n",
    "cbar.ax.set_xticklabels(mod_ticks)\n",
    "\n",
    "ax[0].set_ylim(extent_slope[2]-10,extent_slope[3]+10)\n",
    "ax[0].set_xlim(extent_slope[0]-10,extent_slope[1]+10)\n",
    "\n",
    "with rasterio.open(\"q_cr.tif\", masked=True) as q_cr:      \n",
    "    qt_digi_colors = ax[1].imshow(a, cmap='Greys',\n",
    "                                 norm=LogNorm(\n",
    "                                 vmin=1e1,\n",
    "                                     vmax=1e5\n",
    "                                 ), \n",
    "                          )\n",
    "    im2 = rasterio.plot.show(a, transform=q_cr.transform,\n",
    "                             cmap='Greys',\n",
    "                             norm=LogNorm(\n",
    "                             vmin=1e1,\n",
    "                             vmax=1e5\n",
    "                             ), \n",
    "                             extent=extent_slope,\n",
    "                             ax=ax[1], alpha=0.9,\n",
    "                             zorder=0)\n",
    "\n",
    "b2 = footprint_2018.boundary.plot(ax=ax[1],  color='r', alpha=0.4, linestyle='--',zorder=1)\n",
    "b1 = points_2018.plot(ax=ax[1],\n",
    "                         color='r',\n",
    "                         markersize=10,\n",
    "                         edgecolor='k',\n",
    "                         linewidth=0.5,\n",
    "                         zorder=2)\n",
    "\n",
    "b3 = footprint_2019.boundary.plot(ax=ax[1],  color='c', alpha=0.4, linestyle='--',zorder=1)\n",
    "b4 = points_2019.plot(ax=ax[1],\n",
    "                         color='c',\n",
    "                         markersize=10,\n",
    "                         edgecolor='k',\n",
    "                         linewidth=0.5,\n",
    "                         zorder=2)\n",
    "\n",
    "cbar = fig.colorbar(qt_digi_colors, ax=ax[1], orientation='horizontal',\n",
    "                    label='Drainage area (m2)',\n",
    "                    fraction=0.04,\n",
    "                    #pad=0.1\n",
    "                   )\n",
    "# mod_ticks = cbar.ax.get_xticks().astype(int).astype(str)\n",
    "# mod_ticks[-1:] = '>60'\n",
    "# cbar.ax.set_xticklabels(mod_ticks)\n",
    "\n",
    "ax[1].set_ylim(7.20625e6,7.2070e6)\n",
    "ax[1].set_xlim(442250,443000)\n",
    "\n",
    "ax[0].locator_params(axis='x', nbins=3)\n",
    "ax[0].locator_params(axis='y', nbins=3)\n",
    "ax[0].set_xlabel(\"Easting\")\n",
    "ax[0].set_ylabel(\"Northing\")\n",
    "\n",
    "ax[1].locator_params(axis='x', nbins=3)\n",
    "ax[1].locator_params(axis='y', nbins=3)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//failure_maps.png\", bbox_inches=\"tight\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric sediment flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.linspace(0.0, 1.0, 50)\n",
    "V0 = 0.05\n",
    "H = 1.0\n",
    "dc = np.array([0.05, 0.20]) #Glade et al 2021 compilation\n",
    "\n",
    "Vh_0 = V0 * np.exp(-h/dc[0])\n",
    "Vh_1 = V0 * np.exp(-h/dc[1])\n",
    "Vh_plug = h*(V0/-H) +0.05\n",
    "\n",
    "slope = 0.268 # tan 15 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = V0 * dc * (1 - np.exp(-H/dc))\n",
    "qs_plug = (1/2)*V0*H\n",
    "\n",
    "K = qs/slope\n",
    "K_plug = qs_plug/slope\n",
    "print(qs, qs_plug)\n",
    "print(K, K_plug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2,4),dpi=200)\n",
    "ax.plot(Vh_0, h)\n",
    "ax.plot(Vh_1, h)\n",
    "ax.plot(Vh_plug, h)\n",
    "ax.set_xlabel(\"Velocity (cm/yr)\")\n",
    "ax.set_ylabel(\"Depth (m)\")\n",
    "ax.set_ylim(1.0,0);\n",
    "#plt.savefig(\".//Teller_47_Figures//Teller_47_Figures_in_progress//velocity_profile.png\", bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Code to only run once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get InSAR displacements and locations as GeoDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "data = []\n",
    "with open(os.path.join(data_path, \"insar_2022//subseasonal_all.txt\")) as read:\n",
    "    for line in read:\n",
    "        start = None; end = None\n",
    "        for i,v in enumerate(line):\n",
    "            if v == \"[\": start = i\n",
    "            if v == \"]\": end = i\n",
    "            if start is not None and end is not None:\n",
    "                data.append(line[start+1:end])\n",
    "                start = None; end = None\n",
    "                \n",
    "with open(os.path.join(data_path, \"insar_2022//subseasonal_all.txt\")) as read:\n",
    "    for line in read:\n",
    "        start = None; end = None\n",
    "        for i,v in enumerate(line):\n",
    "            start = 0\n",
    "            if v == \"[\": end = i\n",
    "            if start is not None and end is not None:\n",
    "                keys.append(line[start:end-1])\n",
    "                start = None; end = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_dict = dict(zip(keys, data))\n",
    "insar_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_only = {key: insar_dict[key] for key in insar_dict.keys()\n",
    "                               & {'point J4', 'point J3', 'point J1', 'point J2', 'point J5'}}\n",
    "insar_locs = pd.DataFrame.from_dict(pts_only, orient=\"index\", columns=['position'])\n",
    "insar_locs['position'] = insar_locs['position'].map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_pts_geom = gpd.points_from_xy([i[1] for i in insar_locs['position']], [i[0] for i in insar_locs['position']], crs=\"EPSG:4326\")\n",
    "insar_pts = gpd.GeoDataFrame(insar_locs, crs=\"EPSG:4326\", geometry=insar_pts_geom)\n",
    "insar_pts.drop(labels=['position'], axis=1).to_file(\"insar_pts.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_2017 = {}\n",
    "dict_2017['year'] = 2017\n",
    "dict_2017['doy'] = [int(i) for i in insar_dict['2017 doy'].split(\",\")]\n",
    "dict_2017['J1'] = [float(i) for i in insar_dict['2017 J1'].split()]\n",
    "dict_2017['J2'] = [float(i) for i in insar_dict['2017 J2'].split()]\n",
    "dict_2017['J3'] = [float(i) for i in insar_dict['2017 J3'].split()]\n",
    "dict_2017['J4'] = [float(i) for i in insar_dict['2017 J4'].split()]\n",
    "dict_2017['J5'] = [float(i) for i in insar_dict['2017 J5'].split()]\n",
    "\n",
    "df_2017 = pd.DataFrame.from_dict(dict_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_2018 = {}\n",
    "dict_2018['year'] = 2018\n",
    "dict_2018['doy'] = [int(i) for i in insar_dict['2018 doy'].split(\",\")]\n",
    "dict_2018['J1'] = [float(i) for i in insar_dict['2018 J1'].split()]\n",
    "dict_2018['J2'] = [float(i) for i in insar_dict['2018 J2'].split()]\n",
    "dict_2018['J3'] = [float(i) for i in insar_dict['2018 J3'].split()]\n",
    "dict_2018['J4'] = [float(i) for i in insar_dict['2018 J4'].split()]\n",
    "dict_2018['J5'] = [float(i) for i in insar_dict['2018 J5'].split()]\n",
    "\n",
    "df_2018 = pd.DataFrame.from_dict(dict_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_2019 = {}\n",
    "dict_2019['year'] = 2019\n",
    "dict_2019['doy'] = [int(i) for i in insar_dict['2019 doy'].split(\",\")]\n",
    "dict_2019['J1'] = [float(i) for i in insar_dict['2019 J1'].split()]\n",
    "dict_2019['J2'] = [float(i) for i in insar_dict['2019 J2'].split()]\n",
    "dict_2019['J3'] = [float(i) for i in insar_dict['2019 J3'].split()]\n",
    "dict_2019['J4'] = [float(i) for i in insar_dict['2019 J4'].split()]\n",
    "dict_2019['J5'] = [float(i) for i in insar_dict['2019 J5'].split()]\n",
    "\n",
    "df_2019 = pd.DataFrame.from_dict(dict_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_df = pd.concat([df_2017, df_2018, df_2019]).reset_index(drop=True)\n",
    "#.melt(id_vars=['year','doy'], var_name='site', value_name='displacement')\n",
    "# Decided melting was cool but would make plotting harder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_df.to_csv(\"insar_site_displacements.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean post-processed dGPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_final = pd.read_csv(os.path.join(data_path,\"Teller_47_Data_dGPS//Target_locations_171819_all_observations.csv\"))\n",
    "# Make a dataframe where the corners and middles of lobe targets are grouped and averaged rendering a single location per target per year\n",
    "average_cleaned_final = cleaned_final.groupby('target_name').mean().reset_index()\n",
    "average_cleaned_final.loc[average_cleaned_final['target_name'].str.contains(\"Target\"),'type'] = 'lobe'\n",
    "average_cleaned_final.loc[average_cleaned_final['target_name'].str.contains(\"t2\"),'type'] = 'gcp'\n",
    "average_cleaned_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_PPM = 0.000925 # depends on a surveys greatest distance from a point to the base (for our surveys, 925 m, or .925 network RTK PPM, in mm)\n",
    "\n",
    "average_cleaned_final['h_uncertainty'] = 0.008 +  survey_PPM # horizontal uncertainty on a single measurement, instrument + PPM \n",
    "average_cleaned_final['v_uncertainty'] = 0.015 +  survey_PPM # vertical uncertainty on a single measurement, instrument + PPM \n",
    "\n",
    "average_cleaned_final['position_uncertainty'] = np.sqrt((average_cleaned_final['h_uncertainty']**2) * cleaned_final.groupby('target_name')['Name_common'].count().values)\n",
    "average_cleaned_final['elevation_uncertainty'] = np.sqrt((average_cleaned_final['v_uncertainty']**2) * cleaned_final.groupby('target_name')['Name_common'].count().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cleaned_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_cleaned_final.to_csv(\".//Teller_47_Data//Teller_47_Data_dGPS//target_locs_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": []
   },
   "source": [
    "## Create topo and slope maps from ArcticDEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are going to build a new slope map from the source DEM since we want to eliminate microtopography from our slope maps. So we coarsen the DEM to 10 meters from 2, then calculate slope on that raster, then upscale that raster back to 2 m so we can compare it with the 2 m drainage area array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# use context manager so DatasetReader and MemoryFile get cleaned up automatically\n",
    "@contextmanager\n",
    "def resample_raster(raster, target_res):\n",
    "    # Forces into original target shape, will rewrite it for a better function later\n",
    "    target_shape=(1979, 1818)\n",
    "    \n",
    "    t = raster.transform\n",
    "\n",
    "    # rescale the metadata\n",
    "    scale = t[0]/target_res\n",
    "    transform = Affine(t.a / scale, t.b, t.c, t.d, t.e / scale, t.f)\n",
    "    \n",
    "    if raster.shape == target_shape:\n",
    "        height = int(raster.height * scale)\n",
    "        width = int(raster.width * scale)\n",
    "    else: \n",
    "        height = target_shape[0]\n",
    "        width = target_shape[1]\n",
    "            \n",
    "\n",
    "    profile = raster.profile\n",
    "    profile.update(transform=transform, driver='GTiff', height=height, width=width)\n",
    "\n",
    "    data = raster.read( # Note changed order of indexes, arrays are band, row, col order not row, col, band\n",
    "            out_shape=(raster.count, height, width),\n",
    "            resampling=Resampling.cubic,\n",
    "        )\n",
    "\n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**profile) as dataset: # Open as DatasetWriter\n",
    "            dataset.write(data)                     \n",
    "            del data\n",
    "\n",
    "        with memfile.open() as dataset:  # Reopen as DatasetReader\n",
    "            yield dataset  # Note yield not return     \n",
    "\n",
    "\n",
    "with rasterio.open(data_path+'Teller_47_Data_Rasters//t47_dem.tif') as src:\n",
    "    with resample_raster(src, target_res=10) as resampled:\n",
    "        print('Orig dims: {}, New dims: {}'.format(src.shape, resampled.shape))\n",
    "        print(repr(resampled))\n",
    "        out_meta = resampled.meta.copy()\n",
    "        with rasterio.open(\"new_dem.tif\",\"w\",**out_meta) as dest:\n",
    "            dest.write(resampled.read(1),1)\n",
    "        \n",
    "        elev_10m = rd.LoadGDAL(\"new_dem.tif\")\n",
    "        new_slope = rd.TerrainAttribute(elev_10m, attrib='slope_degrees')\n",
    "\n",
    "        with rasterio.open(\"new_slope.tif\",\"w\",**out_meta) as dest:\n",
    "            print('Slope dims: {}'.format(dest.shape))\n",
    "            dest.write(new_slope, 1) #https://gis.stackexchange.com/questions/279953/numpy-array-to-gtiff-using-rasterio-without-source-raster\n",
    "        #plt.imshow(new_slope)\n",
    "        \n",
    "        with rasterio.open(\"new_slope.tif\") as src:\n",
    "            with resample_raster(src, target_res=2) as resampled:\n",
    "                print('Orig dims: {}, New dims: {}'.format(src.shape, resampled.shape))\n",
    "                print(repr(resampled))\n",
    "                out_meta = resampled.meta.copy()\n",
    "                with rasterio.open(\"new_slope_2m.tif\",\"w\",**out_meta) as dest:\n",
    "                    dest.write(resampled.read(1),1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#https://gis.stackexchange.com/questions/329434/creating-an-in-memory-rasterio-dataset-from-numpy-array/329439#329439\n",
    "#with edits by me to turn height and width to integer if you want to downscale\n",
    "#and automated scaling after providing desired output resolution (a little more intuitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with rasterio.open(data_path+'Teller_47_Data_Rasters//t47_dem.tif') as src:\n",
    "    print(src.shape)\n",
    "    print(src.transform)\n",
    "    print(src.bounds)\n",
    "    src.close()\n",
    "with rasterio.open('new_slope_2m.tif') as src:\n",
    "    print(src.shape)\n",
    "    print(src.transform)\n",
    "    print(src.bounds)\n",
    "    src.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I think I've done it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('seward': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "de07225e13ddb73c9cd13a26ee9d3169fcbb91797d840028ed280be75ae46c87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
